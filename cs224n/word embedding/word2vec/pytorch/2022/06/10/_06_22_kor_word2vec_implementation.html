<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Word2Vec Implementation | WJL in NLP</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Word2Vec Implementation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Word2Vec SGNS(Skip-Gram Negative Sampling) 구현하기" />
<meta property="og:description" content="Word2Vec SGNS(Skip-Gram Negative Sampling) 구현하기" />
<link rel="canonical" href="https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html" />
<meta property="og:url" content="https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html" />
<meta property="og:site_name" content="WJL in NLP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-10T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Word2Vec Implementation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-06-10T00:00:00-05:00","datePublished":"2022-06-10T00:00:00-05:00","description":"Word2Vec SGNS(Skip-Gram Negative Sampling) 구현하기","headline":"Word2Vec Implementation","mainEntityOfPage":{"@type":"WebPage","@id":"https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html"},"url":"https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/nlp_log/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://wjlee-ling.github.io/nlp_log/feed.xml" title="WJL in NLP" /><link rel="shortcut icon" type="image/x-icon" href="/nlp_log/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/nlp_log/">WJL in NLP</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/nlp_log/about/">About Me</a><a class="page-link" href="/nlp_log/search/">Search</a><a class="page-link" href="/nlp_log/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Word2Vec Implementation</h1><p class="page-description">Word2Vec SGNS(Skip-Gram Negative Sampling) 구현하기</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-06-10T00:00:00-05:00" itemprop="datePublished">
        Jun 10, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/nlp_log/categories/#cs224n">cs224n</a>
        &nbsp;
      
        <a class="category-tags-link" href="/nlp_log/categories/#word embedding">word embedding</a>
        &nbsp;
      
        <a class="category-tags-link" href="/nlp_log/categories/#word2vec">word2vec</a>
        &nbsp;
      
        <a class="category-tags-link" href="/nlp_log/categories/#pytorch">pytorch</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/wjlee-ling/nlp_log/tree/master/_notebooks/2022_06_22_kor_word2vec_implementation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/nlp_log/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/wjlee-ling/nlp_log/blob/master/_notebooks/2022_06_22_kor_word2vec_implementation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/nlp_log/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Corpus-&-Tokenization">Corpus &amp; Tokenization </a></li>
<li class="toc-entry toc-h2"><a href="#Skip-Gram-Negative-Sampling">Skip-Gram Negative Sampling </a></li>
<li class="toc-entry toc-h2"><a href="#SKNS-모델">SKNS 모델 </a></li>
<li class="toc-entry toc-h2"><a href="#모델-평가">모델 평가 </a>
<ul>
<li class="toc-entry toc-h3"><a href="#수정사항">수정사항 </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022_06_22_kor_word2vec_implementation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Pytorch로 Word2Vec의 SGNS 구현해 보았다.</p>
<ul>
<li>reference:</li>
</ul>
<ol>
<li>
<a href="https://arxiv.org/pdf/1310.4546.pdf">SGNS 논문</a>  (Mikolov et al. 2013)</li>
<li><a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb">word2vec official notebook</a></li>
</ol>
<p><a href="https://www.jasonosajima.com/ns.html">https://www.jasonosajima.com/ns.html</a>
<a href="http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/">http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sentencepiece</span> <span class="k">as</span> <span class="nn">spm</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">main_dir</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">"/content/drive/MyDrive/Colab Notebooks/nlp/a2"</span> <span class="c1"># 이 notebook이 저장된 폴더 주소</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">main_dir</span><span class="p">)</span> 
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Corpus-&amp;-Tokenization">
<a class="anchor" href="#Corpus-&amp;-Tokenization" aria-hidden="true"><span class="octicon octicon-link"></span></a>Corpus &amp; Tokenization<a class="anchor-link" href="#Corpus-&amp;-Tokenization"> </a>
</h2>
<p><a href="https://github.com/google/sentencepiece">SentencePiece</a>로 Unigram Wordpiece로 한국어 word2vec를 진행했다. 훈련 데이터는 모두의말뭉치-신문기사(2021, 조선일보, 140MB)의 일부이다. 사전 크기는 5,000으로 정했으며, 추후 사용할 수 있게끔 special tokens (e.g. [PAD], [SEP], etc)도 사전에 등록하였다 (훈련은 안함).</p>
<ul>
<li>참고:</li>
</ul>
<ol>
<li><a href="https://github.com/google/sentencepiece/tree/master/python">https://github.com/google/sentencepiece/tree/master/python</a></li>
<li><a href="https://github.com/paul-hyun/transformer-evolution/blob/master/tutorial/vocab_with_sentencepiece.ipynb">https://github.com/paul-hyun/transformer-evolution/blob/master/tutorial/vocab_with_sentencepiece.ipynb</a></li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'/content/drive/MyDrive/A2_TeamProject/data/cleaned_모두의말뭉치/모두의말뭉치-조선일보.csv'</span><span class="p">)</span>
<span class="n">corpus</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">'topic'</span><span class="p">)</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-dc2d9793-007b-4fce-9ece-26dedca80b86">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>newpaper</th>
      <th>title</th>
      <th>body</th>
      <th>written_at</th>
    </tr>
    <tr>
      <th>topic</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>IT/과학</th>
      <td>1</td>
      <td>2937</td>
      <td>19457</td>
      <td>605</td>
    </tr>
    <tr>
      <th>경제</th>
      <td>1</td>
      <td>5530</td>
      <td>35929</td>
      <td>668</td>
    </tr>
    <tr>
      <th>문화</th>
      <td>1</td>
      <td>1690</td>
      <td>8345</td>
      <td>541</td>
    </tr>
    <tr>
      <th>미용/건강</th>
      <td>1</td>
      <td>2569</td>
      <td>17585</td>
      <td>578</td>
    </tr>
    <tr>
      <th>사회</th>
      <td>1</td>
      <td>13362</td>
      <td>82599</td>
      <td>710</td>
    </tr>
    <tr>
      <th>생활</th>
      <td>1</td>
      <td>4831</td>
      <td>31584</td>
      <td>677</td>
    </tr>
    <tr>
      <th>스포츠</th>
      <td>1</td>
      <td>2983</td>
      <td>18621</td>
      <td>625</td>
    </tr>
    <tr>
      <th>연예</th>
      <td>1</td>
      <td>326</td>
      <td>1837</td>
      <td>251</td>
    </tr>
    <tr>
      <th>정치</th>
      <td>1</td>
      <td>4344</td>
      <td>24469</td>
      <td>631</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-dc2d9793-007b-4fce-9ece-26dedca80b86')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none"></path>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"></path><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"></path>
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-dc2d9793-007b-4fce-9ece-26dedca80b86 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-dc2d9793-007b-4fce-9ece-26dedca80b86');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>다양한 범주의 본문을 random하게 추출하여 학습데이터를 만들었고, 구두점이나 기호들을 제거했다. 구두점/기호들은 대개 문맥적으로 의미가 떨어지는 한편, 그 수가 너무 많아 오버샘플링 된다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="s1">'body'</span><span class="p">][</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c1">#기사의 본문만 추출해 사용.</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">paragraph</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="n">paragraph</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)</span> <span class="c1"># 사용한 corpus의 단위가 paragraph 기반이라 sentence기반으로 바꿈.</span>
    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sent</span> <span class="o">==</span> <span class="s1">''</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">sent</span> <span class="o">=</span> <span class="n">sent</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">punc</span> <span class="ow">in</span> <span class="s2">".,!?</span><span class="se">\"</span><span class="s2">'_-$^&amp;*()</span><span class="si">{}</span><span class="s2">[]&lt;&gt;/#+=</span><span class="se">\\</span><span class="s2">:;"</span><span class="p">:</span> 
            <span class="n">sent</span> <span class="o">=</span> <span class="n">sent</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">punc</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span>
        <span class="n">sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> 
<span class="n">corpus_text</span> <span class="o">=</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="c1"># SentencePiece는 input으로 one-sentence-per-line 요구함</span>
<span class="c1"># 확인</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">[:</span><span class="mi">3</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'KorNews.txt'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">corpus_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>선택권을 가진 미위팅이 백번을 선택했다
요즘 고수들의 초반 포석은 마치 복기를 구경하는 것 같다
패턴화한 10여 개 남짓의 정석이 반상에 반복적으로 주르르 펼쳐진다
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Word2Vec은 원래 word 단위로 학습되었고, 두 어절 이상의 단어(예시 'White House')들 중 몇 개는 따로 사전에 등록해서 하나의 단위로 학습하게끔 했다.</p>
<p>그러나 고립어인 영어와 달리, 한국어는 교착어로 조사/어미가 복잡하고 어절 단위로 사전을 구성하기에 부적합하기 때문에 여기서는 SentencePiece를 사용하여 단어 보다 작은 subword 단위로 토큰화하여 사전을 구성하려고 한다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">spm</span><span class="o">.</span><span class="n">SentencePieceTrainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s1">'KorNews.txt'</span><span class="p">,</span> <span class="n">model_prefix</span><span class="o">=</span><span class="s1">'KorNews_Unigram'</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="s1">'unigram'</span><span class="p">,</span>\
                               <span class="n">pad_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_piece</span><span class="o">=</span><span class="s2">"[PAD]"</span><span class="p">,</span> <span class="n">unk_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">unk_piece</span><span class="o">=</span><span class="s2">"[UNK]"</span><span class="p">,</span> <span class="n">bos_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bos_piece</span><span class="o">=</span><span class="s2">"[BOS]"</span><span class="p">,</span> <span class="n">eos_id</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eos_piece</span><span class="o">=</span><span class="s2">"[EOS]"</span><span class="p">,</span>\
                               <span class="n">user_defined_symbols</span><span class="o">=</span><span class="p">[</span><span class="s2">"[SEP]"</span><span class="p">,</span> <span class="s2">"[CLS]"</span><span class="p">,</span> <span class="s2">"[MASK"</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sp</span> <span class="o">=</span> <span class="n">spm</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">()</span>
<span class="n">sp</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">main_dir</span><span class="p">,</span> <span class="s2">"KorNews_Unigram.model"</span><span class="p">))</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">sp</span><span class="o">.</span><span class="n">id_to_piece</span><span class="p">(</span><span class="nb">id</span><span class="p">):</span> <span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">get_piece_size</span><span class="p">())}</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">add_bos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_eos</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Skip-Gram-Negative-Sampling">
<a class="anchor" href="#Skip-Gram-Negative-Sampling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Skip-Gram Negative Sampling<a class="anchor-link" href="#Skip-Gram-Negative-Sampling"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Error Distribution</strong></p>
<p>논문에서 negative sampling에 필요한 error distribution을 구할 때 다음과 같은 확률을 이용한다. 
$$
P_n(w_i) = \frac{U(w_i)^{3/4}}{\sum_{j=0}^{n}U(w_j)^{3/4}}
$$
$U(w_i)$는 unigram probability이다.</p>
<p>위 공식으로 각 단어가 추출될 확률을 구해 <code>probs</code>라는 변수에 저장한다. 해당 변수는 위에서 지정한 word2id의 인덱스를 따른다. (즉 [UNK], [SOS], [EOS] 토큰은 각각 0,1,2의 인덱스 가짐). 이 확률을 이용하여 negative example의 사전 id를 구하려면</p>
<ol>
<li>python 내장 random 라이브러리의 choices 함수를 사용하거나 </li>
<li>numpy.random.choice를 이용하면 된다 (이 경우에는 k만큼 반복)</li>
<li>
<a href="https://ethankoch.medium.com/incredibly-fast-random-sampling-in-python-baf154bd836a">matrix 사용하는 방법</a>. 위 두 방법이 가장 간단하나 시간이 너무 오래 걸려 찾아 보았다. 이 방식은 1/2번 보다 훨씬 빠르나, 내 경우엔 vocab_size가 너무 커서 (vocab_size, vocab_size)만큼 생성할 때 부담.</li>
</ol>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">numpy</span>
<span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">))</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">weigths</span><span class="o">=</span><span class="n">probs</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="c1"># 1번</span>
<span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span> <span class="c1"># 2번</span>
</pre></div>
<p>윗 방법들이 시간/물리적으로 부담이 크기에 gensim의 <a href="https://github.com/RaRe-Technologies/gensim/blob/ded78776284ad7b55b6626191eaa8dcea0dd3db0/gensim/models/word2vec.py#L822">word2vec 코드</a><strong>Word2Vec.make_cum_table()</strong>를 보고 참고한 sampling 방법이 아래 <strong>Skipgram._create_cumsum_table()</strong>과 <strong>Skipgram.sample_negatives()</strong>이다. 이 방법은 위 공식의 $P(w_i)$를 누적시킨 확률 array를 만들어 놓고, [0,1] 사이의 난수를 bisection-left방식 (np.searchsorted 참고)으로 누적 확률 array에 비교시켜 결과로 얻은 인덱스를 샘플링할 단어의 인덱스로 여기는 것이다. 
예를 들어 사전 크기가 3이고 각 단어들의 샘플링 확률(0.75승 하여 완만하게 만든 확률)이 [0.1, 0.3, 0.6]일 때, cumsum_table은 [0.1, 0.4(=0.1+0.3), 1.0(=0.1+0.3+0.6)]이다. 생성한 난수가 0.28일 때 이 난수와 cumsum_table로 bisection search(left)를 하면 이 난수가 속할 section은 두번째 섹션(b/c 0.1 &lt; <strong>0.28</strong> &lt;= 0.4)이므로 negative sample로 추출할 단어 인덱스는 1이다.</p>
<p><strong>Subsampling Probability</strong>
$$
P(w_i) = 1 - \sqrt{\frac{t}{f(w_i)}}
$$
논문에서는 빈도가 매우 높은 단어의 경우 오버샘플링 되어 빈도수가 적은 단어들보다 훨씬 업데이트가 될 가능성이 높은 만큼, 각 단어의 샘플링 추출 확률을 정해 훈련했다고 한다. 위 확률은 추출되지 않을 확률이다. t는 임의로 정하는 값이며, 논문에서는 1e-5로 했으나 나는 1e-4로 했다 (gensim은 (0,1e-5]의 값).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">n_neg_samples</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># 'k' in the paper; # of negative samples per each pair (center word, positive context word)</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># i.e. 2*2 context words. 원래는 center + 앞/뒤 context words를 다 포함하는 크기</span>

<span class="k">class</span> <span class="nc">SkipgramSampler</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">vocab</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        Args:</span>
<span class="sd">            - tokens: List[List]. Each nested list should account for a sentence.</span>
<span class="sd">            - vocab: Dict{word:id}. Word2id</span>
<span class="sd">        '''</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span> <span class="c1"># word2id</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'vocab_size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id2word</span> <span class="o">=</span> <span class="p">{</span><span class="nb">id</span><span class="p">:</span> <span class="n">w</span> <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">_get_freq</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        get frequency of words</span>
<span class="sd">        '''</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="c1"># update counter</span>
        <span class="k">for</span> <span class="n">sent_tokens</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokens</span><span class="p">:</span>
            <span class="n">counter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">sent_tokens</span><span class="p">)</span>
        <span class="c1"># calculate pure counts</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">counts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">counter</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">counts</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="n">freq</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">freq</span>

    <span class="k">def</span> <span class="nf">_get_negative_sampling_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">freq</span><span class="p">):</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">freq</span><span class="o">**</span><span class="mf">0.75</span>
        <span class="n">probs</span> <span class="o">/=</span> <span class="n">probs</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>           
        <span class="k">return</span> <span class="n">probs</span>

    <span class="k">def</span> <span class="nf">_get_sub_sampling_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">freq</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mf">3e-5</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        논문의 공식과 다르게 버려질 확률이 아닌 뽑힐 확률. 논문에서는 t=1e-5</span>
<span class="sd">        '''</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">t</span> <span class="o">/</span> <span class="n">freq</span><span class="p">)</span> <span class="c1">#-np.sqrt(probs**-1 * 1e-5 ) + 1</span>
        <span class="k">return</span> <span class="n">probs</span>

    <span class="k">def</span> <span class="nf">_create_cumsum_table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">freq</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        vocab 인덱스를 따름. 단어별 sampling 축적 확률.</span>
<span class="sd">        '''</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_negative_sampling_prob</span><span class="p">(</span><span class="n">freq</span><span class="p">)</span>
        <span class="n">cumsum_table</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">cumsum_table</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.</span> <span class="o">&lt;=</span> <span class="mf">1e-5</span>
        <span class="k">return</span> <span class="n">cumsum_table</span>

    <span class="k">def</span> <span class="nf">sample_skipgrams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">window_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        Args:</span>
<span class="sd">            - window_size: 2*window_size context words for each target word</span>
<span class="sd">            - k: num of the negative pairs per each true context word</span>
<span class="sd">            - return_ids : id로 출력 혹은 word(str)로 출력</span>
<span class="sd">        Return:</span>
<span class="sd">            - pairs: [center_word, positive_context_word, negative_context_word_1, ..., negative_context_word_k]</span>
<span class="sd">        '''</span>
        <span class="n">pairs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">freq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_freq</span><span class="p">()</span>
        <span class="n">subsampling_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sub_sampling_prob</span><span class="p">(</span><span class="n">freq</span><span class="p">)</span>
        <span class="n">negsampling_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_negative_sampling_prob</span><span class="p">(</span><span class="n">freq</span><span class="p">)</span>
        <span class="n">cumsum_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_cumsum_table</span><span class="p">(</span><span class="n">negsampling_probs</span><span class="p">)</span>
        <span class="n">discarded</span><span class="p">,</span> <span class="n">saved</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokens</span><span class="p">):</span>
            <span class="n">sent_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">center_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sent</span><span class="p">):</span>
                <span class="n">idx_start</span> <span class="o">=</span> <span class="n">idx</span><span class="o">-</span><span class="n">window_size</span> <span class="k">if</span> <span class="n">idx</span><span class="o">-</span><span class="n">window_size</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
                <span class="n">idx_end</span> <span class="o">=</span> <span class="n">idx</span><span class="o">+</span><span class="n">window_size</span><span class="o">+</span><span class="mi">1</span> <span class="k">if</span> <span class="n">idx</span><span class="o">+</span><span class="n">window_size</span><span class="o">+</span><span class="mi">1</span> <span class="o">&lt;</span> <span class="n">sent_len</span> <span class="k">else</span> <span class="n">sent_len</span>
                <span class="n">window</span> <span class="o">=</span> <span class="n">sent</span><span class="p">[</span><span class="n">idx_start</span><span class="p">:</span><span class="n">idx_end</span><span class="p">]</span>
                <span class="n">pos_ids</span> <span class="o">=</span> <span class="p">[</span><span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">window</span> <span class="k">if</span> <span class="nb">id</span> <span class="o">!=</span> <span class="n">center_id</span><span class="p">]</span>
                <span class="n">random_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">))</span>
                <span class="n">pos_sub_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">subsampling_probs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">pos_ids</span><span class="p">])</span>
                <span class="n">pos_sub_probs</span> <span class="o">=</span> <span class="p">(</span><span class="n">random_probs</span> <span class="o">&lt;=</span> <span class="n">pos_sub_probs</span><span class="p">)</span> <span class="c1"># if to be sampled, True</span>

                <span class="k">for</span> <span class="n">pos_id</span><span class="p">,</span> <span class="n">pos_sub_prob</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pos_ids</span><span class="p">,</span> <span class="n">pos_sub_probs</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">pos_sub_prob</span><span class="p">:</span>
                        <span class="n">discarded</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">continue</span>
                    <span class="n">saved</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">neg_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_negatives</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">cumsum_table</span><span class="p">,</span> <span class="p">[</span><span class="n">center_id</span><span class="p">]</span><span class="o">+</span> <span class="n">pos_ids</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">return_ids</span><span class="p">:</span>
                        <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">center_id</span><span class="p">,</span> <span class="n">pos_id</span><span class="p">])</span>
                        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">neg_id</span> <span class="ow">in</span> <span class="n">neg_ids</span><span class="p">:</span>
                            <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">center_id</span><span class="p">,</span> <span class="n">neg_id</span><span class="p">])</span>
                            <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="p">[</span><span class="n">center_id</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="p">[</span><span class="n">pos_id</span><span class="p">]])</span>
                        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">neg_ids</span><span class="p">]:</span>
                            <span class="n">pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">id2word</span><span class="p">[</span><span class="n">center_id</span><span class="p">],</span> <span class="n">w</span><span class="p">])</span>
                            <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">saved: </span><span class="si">{</span><span class="n">saved</span><span class="si">}</span><span class="s1"> discarded: </span><span class="si">{</span><span class="n">discarded</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="nf">sample_negatives</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">cumsum_table</span><span class="p">,</span> <span class="n">exceptions</span><span class="p">):</span>
        <span class="sd">'''</span>
<span class="sd">        unique하게 negaitve samples를 추출. center word와 true context words (i.e.exceptions)는 제거.</span>
<span class="sd">        '''</span>
        <span class="n">neg_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">exceptions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">exceptions</span><span class="p">)</span>
        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">k</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">neg_ids</span><span class="p">))</span>
            <span class="c1">#ids = self.random.choices(list(range(self.vocab_size)), weights=probabilities, k=k-len(neg_ids))</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">cumsum_table</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">side</span><span class="o">=</span><span class="s1">'left'</span><span class="p">)</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">exceptions</span><span class="p">)</span> <span class="c1">#unique하게 됨</span>
            <span class="n">neg_ids</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">neg_ids</span>

<span class="n">ss</span> <span class="o">=</span> <span class="n">SkipgramSampler</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="n">pairs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">sample_skipgrams</span><span class="p">(</span><span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">n_neg_samples</span><span class="p">,</span> <span class="n">return_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'positive examples: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s1"> &amp; negative examples: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>vocab_size: 10000
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 35174/35174 [01:26&lt;00:00, 405.61it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
saved: 1340766 discarded: 2283114
positive examples: 1340766 &amp; negative examples: 13407660
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>총 10,000 문장에서 positive: 1,340,766 단어쌍, negative: 13,407,660 단어쌍을 추출하였다.</p>
<p>오랜 시간 걸려 추출한 n-gram samples을 저장하려면</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># write</span>
<span class="n">pairs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'center_words'</span><span class="p">:</span> <span class="n">centers</span><span class="p">,</span> <span class="s1">'context_words'</span><span class="p">:</span><span class="n">contexts</span><span class="p">}</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">main_dir</span><span class="p">,</span> <span class="s1">'KorNews_SGNS_Pairs.json'</span><span class="p">),</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="c1"># read</span>
<span class="n">json_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">main_dir</span><span class="p">,</span> <span class="s2">"KorNews_SGNS_Pairs.json"</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">json_dir</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pairs_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="c1"># pairs_dict['center_words']</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">SKNS_Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pairs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pairs</span> <span class="o">=</span> <span class="n">pairs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pairs</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairs</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairs</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">SKNS_Dataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span><span class="n">labels</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">test_size</span><span class="p">])</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">del</span> <span class="n">dataset</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="SKNS-모델">
<a class="anchor" href="#SKNS-%EB%AA%A8%EB%8D%B8" aria-hidden="true"><span class="octicon octicon-link"></span></a>SKNS 모델<a class="anchor-link" href="#SKNS-%EB%AA%A8%EB%8D%B8"> </a>
</h2>
<p></p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>항상 pytorch를 사용했었는데, 이번엔 좀 더 빠르고 가볍다는 <a href="%22https://github.com/PyTorchLightning/pytorch-lightning%22">pytorch-lightning</a>을 이용해 훈련해보기로 했다. 기존에는 1) model 클래스와 인스턴스 만들고 dataloader-loop 안에서 2) loss계산과 back-propagation 3)checkpoint saving 을 하는 코드를 일일히 따로 작성해야 한다. 그런데  라이트닝에서는 model 클래스만 지정해주면 제공되는 Trainer를 이용해 간단히 훈련시킬 수 있다.  
</div>
Word2Vec은 사전 인덱스를 이용한 one-hot embedding이 아니라, 각 단어마다 300차원의 벡터를 생성하고 훈련시킨다. dataloader로 사전 인덱스를 배치로 받기 때문에 해당 인덱스에 해당하는 n-차원의 벡터로 바꿔주는 nn.Embedding layer를 사용한다. Word2Vec은 같은 단어가 센터(타겟)냐 컨텍스트냐에 따라 다른 벡터를 갖기 때문에 (vocab_size, embedding_size)의 임베딩 텐서를 두 개 생성해야 한다.

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span><span class="p">,</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">256</span> <span class="c1"># 논문은 300 </span>

<span class="n">center_vecs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">context_vecs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SKNS</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">center_vecs</span><span class="p">,</span> <span class="n">context_vecs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centers</span> <span class="o">=</span> <span class="n">center_vecs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">contexts</span> <span class="o">=</span> <span class="n">context_vecs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centers</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">center_ids</span><span class="p">,</span> <span class="n">context_ids</span><span class="p">):</span>
        <span class="c1"># in lightning, forward defines the prediction/inference actions</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">center_ids</span><span class="p">)</span>
        <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">centers</span><span class="p">(</span><span class="n">center_ids</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># (batch, embedding) -&gt; (batch, embed, 1)</span>
        <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contexts</span><span class="p">(</span><span class="n">context_ids</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_size</span><span class="p">)</span> <span class="c1"># (batch, embedding) -&gt; (batch, 1, embed)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># (batch, 1, 1) =&gt; (batch)</span>
        <span class="k">return</span> <span class="n">logits</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># training_step defines the train loop. It is independent of forward</span>
        <span class="n">center_ids</span><span class="p">,</span> <span class="n">context_ids</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">center_ids</span><span class="p">,</span> <span class="n">context_ids</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">"train_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">center_ids</span><span class="p">,</span> <span class="n">context_ids</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">center_ids</span><span class="p">,</span> <span class="n">context_ids</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">"valid_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span><span class="mf">0.95</span> <span class="o">**</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">"optimizer"</span><span class="p">:</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="s2">"lr_scheduler"</span><span class="p">:</span><span class="n">scheduler</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">centers</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">contexts</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SKNS</span><span class="p">(</span><span class="n">center_vecs</span><span class="p">,</span> <span class="n">context_vecs</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s1">'gpu'</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>loss 함수로 쓴 nn.BCEWithLogitsLoss() 는 binary classification에 쓸 수 있는 함수로 log(simoid(x)) 한 loss값을 계산해준다.label의 dtype은 int가 아닌 float이여야 한다.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pl</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">garbage_collection_cuda</span><span class="p">()</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">)</span> <span class="c1"># DataLoader 객체가 아닌 따른 Iterator여도 됨.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type              | Params
-----------------------------------------------
0 | centers  | Embedding         | 2.6 M 
1 | contexts | Embedding         | 2.6 M 
2 | loss_fn  | BCEWithLogitsLoss | 0     
-----------------------------------------------
5.1 M     Trainable params
0         Non-trainable params
5.1 M     Total params
10.240    Total estimated model params size (MB)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> tensorboard
<span class="o">%</span><span class="k">tensorboard</span> --logdir=lightning_logs/
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>Output hidden; open in https://colab.research.google.com to view.</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="모델-평가">
<a class="anchor" href="#%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80" aria-hidden="true"><span class="octicon octicon-link"></span></a>모델 평가<a class="anchor-link" href="#%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80"> </a>
</h2>
<p>gensim을 이용하여 유의어/반의어 및 analogy test를 할 수 있다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gensim</span>
<span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="n">contexts</span><span class="p">)</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'KorNews_w2v_V.txt'</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">vocab_size</span><span class="o">-</span><span class="mi">1</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">embedding_dim</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">w</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="s2">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">centers</span><span class="p">[</span><span class="n">ind</span><span class="p">,:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="p">))</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">w2v</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">'KorNews_w2v_V.txt'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>결과를 보면 어느 정도 학습이 된 것으로 보인다. 그러나 코퍼스의 출처가 작년 신문 기사다 보니 정치 관련 단어들은 비교적 학습이 잘 된 반면, 일반명사나 동사, 부사 등은 학습이 아쉬워 보인다. 게다가 subword 토크나이저는 대개 어절의 맨 앞에 나타나는 경우('▁중국')와 아닌 경우('중국')로 나눠 사전을 구성하는데, 두 경우다 제대로 훈련시키는 것도 해결해야할 과제이다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">'▁중국'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('▁한국', 0.41443902254104614),
 ('▁미국', 0.4098540246486664),
 ('▁일본', 0.38627344369888306),
 ('▁세계', 0.3704119026660919),
 ('▁20', 0.34667396545410156),
 ('▁선수', 0.34340745210647583),
 ('▁7', 0.3106424808502197),
 ('▁트럼프', 0.3065921664237976),
 ('▁국내', 0.3052994906902313),
 ('▁우리', 0.30426502227783203)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">'중국'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('▁영', 0.27694588899612427),
 ('마케팅', 0.2600131928920746),
 ('▁기자들', 0.2560494542121887),
 ('▁샘플', 0.24935927987098694),
 ('▁밖에', 0.24410425126552582),
 ('홍보관', 0.24130752682685852),
 ('▁신한카드', 0.2389327883720398),
 ('벼', 0.2308148890733719),
 ('셧', 0.22932805120944977),
 ('▁의견이', 0.22786958515644073)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">'▁대통령'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('▁청와대', 0.3450790047645569),
 ('▁장관', 0.3396446704864502),
 ('▁의원', 0.32314038276672363),
 ('▁이후', 0.3140028119087219),
 ('▁대통령이', 0.3101692497730255),
 ('▁민주당', 0.30879759788513184),
 ('▁정부', 0.3069238066673279),
 ('▁문', 0.3028714060783386),
 ('엔', 0.29196697473526),
 ('▁미국', 0.28609851002693176)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">'▁트럼프'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('▁미', 0.358543336391449),
 ('▁대통령이', 0.3487488031387329),
 ('▁북한', 0.3468424677848816),
 ('▁일본', 0.31102779507637024),
 ('▁미국', 0.31074368953704834),
 ('▁중국', 0.3065921664237976),
 ('▁지난달', 0.2924591600894928),
 ('▁총리', 0.2919672429561615),
 ('▁대통령', 0.2834343910217285),
 ('▁검찰', 0.26758497953414917)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">'▁내년'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('▁지난해', 0.2932113707065582),
 ('▁9', 0.2712252736091614),
 ('▁이날', 0.2705169916152954),
 ('▁온라인', 0.2697073817253113),
 ('▁올해', 0.2610678970813751),
 ('▁2021', 0.2584304213523865),
 ('▁AP', 0.25618451833724976),
 ('▁감염자', 0.2545149326324463),
 ('학년도', 0.24879765510559082),
 ('▁이어', 0.24502748250961304)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">'을'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('를', 0.4446668028831482),
 ('으로', 0.3875734508037567),
 ('이', 0.3176490068435669),
 ('고', 0.2827107608318329),
 ('도', 0.25626111030578613),
 ('은', 0.254934698343277),
 ('에', 0.25474870204925537),
 ('▁것', 0.23995378613471985),
 ('하는', 0.2388738989830017),
 ('과', 0.2370939552783966)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">'한다'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('했다', 0.48733481764793396),
 ('할', 0.44905075430870056),
 ('하는', 0.4311229884624481),
 ('하고', 0.4263955354690552),
 ('해', 0.4139285683631897),
 ('됐다', 0.40646255016326904),
 ('하기', 0.3861447274684906),
 ('될', 0.3859519362449646),
 ('돼', 0.3652912378311157),
 ('하면서', 0.3618863821029663)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w2v</span><span class="o">.</span><span class="n">most_similar</span><span class="p">([</span><span class="s1">'▁군'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('산', 0.3136850595474243),
 ('▁다른', 0.2931358218193054),
 ('▁주', 0.29162198305130005),
 ('▁지난해', 0.28887131810188293),
 ('▁청와대', 0.2820741534233093),
 ('▁장', 0.2817824184894562),
 ('▁문제', 0.27845048904418945),
 ('▁20', 0.27788224816322327),
 ('▁기', 0.2763606011867523),
 ('▁대해', 0.26905715465545654)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="수정사항">
<a class="anchor" href="#%EC%88%98%EC%A0%95%EC%82%AC%ED%95%AD" aria-hidden="true"><span class="octicon octicon-link"></span></a>수정사항<a class="anchor-link" href="#%EC%88%98%EC%A0%95%EC%82%AC%ED%95%AD"> </a>
</h3>
<ol>
<li>더 많은 학습데이터로 추가 학습 (문장 10,000개 선정하여 사전 만들고 및 학습하였음.)</li>
<li>혹은 사전 크기를 줄이기</li>
</ol>

</div>
</div>
</div>
</div>

<script type="application/vnd.jupyter.widget-state+json">
{"8a9c2105f5814a92a69825acf0018661": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_1e710d84ab334622b95155be806ef394", "IPY_MODEL_35c06c4a66524caebc053c62d1ab4948", "IPY_MODEL_b09e00c5e9ea4073b1df2b582de68222"], "layout": "IPY_MODEL_70c734de92ed46e087551d259abcbd8e"}}, "1e710d84ab334622b95155be806ef394": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_21fa44ed88d741d1988df99cb74af9ac", "placeholder": "\u200b", "style": "IPY_MODEL_6ffe7e3c23384c64b965aee3a94e426e", "value": "Sanity Checking DataLoader 0: 100%"}}, "35c06c4a66524caebc053c62d1ab4948": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_59b6c428a27042e19dc50a6d10cd1c6c", "max": 2, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_fe37676073624640b9fd1a478e4108d7", "value": 2}}, "b09e00c5e9ea4073b1df2b582de68222": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_9535a0564d564172b58ba5fcb6de9ba1", "placeholder": "\u200b", "style": "IPY_MODEL_24f15323d9ee4da4a2ecddb2e586d309", "value": " 2/2 [00:00&lt;00:00, 79.96it/s]"}}, "70c734de92ed46e087551d259abcbd8e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "21fa44ed88d741d1988df99cb74af9ac": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6ffe7e3c23384c64b965aee3a94e426e": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "59b6c428a27042e19dc50a6d10cd1c6c": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fe37676073624640b9fd1a478e4108d7": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "9535a0564d564172b58ba5fcb6de9ba1": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "24f15323d9ee4da4a2ecddb2e586d309": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "88c35f64df754c6cabc65ea662593c8c": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_c2371d6cf3514042910d707d2ca65da5", "IPY_MODEL_8178cbc220b446aba0e7f73d0b5c75cf", "IPY_MODEL_9071c7dacce345c989b6794c127f8822"], "layout": "IPY_MODEL_85b01b86c24c4537b516bafda17784c0"}}, "c2371d6cf3514042910d707d2ca65da5": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_a4c397cc35064bd9be3bf7bbfd81a0d5", "placeholder": "\u200b", "style": "IPY_MODEL_a4aadde0d9a64030a4dda6fefa62b1bc", "value": "Epoch 4: 100%"}}, "8178cbc220b446aba0e7f73d0b5c75cf": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_901c0817b05c46339d6c528be4b98a3c", "max": 253490, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_81b9b8bebf9a4c2f8babbe22932b9373", "value": 253490}}, "9071c7dacce345c989b6794c127f8822": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_d0a7c1daf1bb453fa7a113798013857d", "placeholder": "\u200b", "style": "IPY_MODEL_6c9a2d8021904b08b8e1f1e35d083e9d", "value": " 253490/253490 [23:47&lt;00:00, 177.55it/s, loss=0.32, v_num=3]"}}, "85b01b86c24c4537b516bafda17784c0": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "a4c397cc35064bd9be3bf7bbfd81a0d5": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a4aadde0d9a64030a4dda6fefa62b1bc": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "901c0817b05c46339d6c528be4b98a3c": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "81b9b8bebf9a4c2f8babbe22932b9373": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "d0a7c1daf1bb453fa7a113798013857d": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6c9a2d8021904b08b8e1f1e35d083e9d": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "070b7832dfc2498699673ae7b5a2ffae": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e5ee2886e00c41a7b56aa8cc828a1ae6", "IPY_MODEL_8d2241074a7b4ce4a2362c55421f0eef", "IPY_MODEL_1512368de94944d09d0c46509c5d9b8a"], "layout": "IPY_MODEL_38ec074565ae44b3a7e5a0ef930f981b"}}, "e5ee2886e00c41a7b56aa8cc828a1ae6": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_0c2c597478924535a3324f2750e4ad68", "placeholder": "\u200b", "style": "IPY_MODEL_514147a6c8b6479c99ce1fe7aeee2ae4", "value": "Validation DataLoader 0: 100%"}}, "8d2241074a7b4ce4a2362c55421f0eef": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_8ce5f9d50ab74a66923bfd52946e3bb2", "max": 23045, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_f2d322f848fe4f35a87395a12f20baba", "value": 23045}}, "1512368de94944d09d0c46509c5d9b8a": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_413c89b3d0a94705a9f8e74225f3eff0", "placeholder": "\u200b", "style": "IPY_MODEL_deaf3227132a4f35ba78c90d474a42fd", "value": " 23045/23045 [01:17&lt;00:00, 287.97it/s]"}}, "38ec074565ae44b3a7e5a0ef930f981b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "0c2c597478924535a3324f2750e4ad68": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "514147a6c8b6479c99ce1fe7aeee2ae4": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "8ce5f9d50ab74a66923bfd52946e3bb2": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f2d322f848fe4f35a87395a12f20baba": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "413c89b3d0a94705a9f8e74225f3eff0": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "deaf3227132a4f35ba78c90d474a42fd": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "161eca1dc55a44e688333f961baa6482": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_6e6829ac4ee1481f87a7dc918367031f", "IPY_MODEL_a28893f7c5604357a6806d2d549a5b3f", "IPY_MODEL_41d96a0879d846e9a03bd6b2f672699d"], "layout": "IPY_MODEL_0f939587defb451581a901ec6ffded6b"}}, "6e6829ac4ee1481f87a7dc918367031f": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_facdc793b6b3417eb4c2b5912af88c7a", "placeholder": "\u200b", "style": "IPY_MODEL_8543a0a4f91d48c79b0ec71cb4d02b80", "value": "Validation DataLoader 0: 100%"}}, "a28893f7c5604357a6806d2d549a5b3f": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_46708846bdf74a95b832b9813a69c700", "max": 23045, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_57952dddcfb44aa2b9a99808a56a7977", "value": 23045}}, "41d96a0879d846e9a03bd6b2f672699d": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_64387c7885774a74ba473056a3a4fe4e", "placeholder": "\u200b", "style": "IPY_MODEL_4f20565f2c7c4c3588bed396d09f8ea2", "value": " 23045/23045 [01:17&lt;00:00, 304.93it/s]"}}, "0f939587defb451581a901ec6ffded6b": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "facdc793b6b3417eb4c2b5912af88c7a": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "8543a0a4f91d48c79b0ec71cb4d02b80": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "46708846bdf74a95b832b9813a69c700": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "57952dddcfb44aa2b9a99808a56a7977": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "64387c7885774a74ba473056a3a4fe4e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4f20565f2c7c4c3588bed396d09f8ea2": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "670a4956c11b450693e2b74d76ed9880": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_cc7878a81bee44a99fd58eaa07ed14ae", "IPY_MODEL_5c0d0ae230fa4ef189f857ffb8239ed0", "IPY_MODEL_64708b649f1e4bbd9a41c40673a14bbb"], "layout": "IPY_MODEL_dc018f1038284d79a2decce740f03d36"}}, "cc7878a81bee44a99fd58eaa07ed14ae": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_153f57c4508940758818674a60edb1ab", "placeholder": "\u200b", "style": "IPY_MODEL_a2209d34b71e43ec971f293d00775bdd", "value": "Validation DataLoader 0: 100%"}}, "5c0d0ae230fa4ef189f857ffb8239ed0": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_dd4d0d9eff5c446a8229832b7461181a", "max": 23045, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_89d08224a32d40b597f02817a1e2e30f", "value": 23045}}, "64708b649f1e4bbd9a41c40673a14bbb": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_4668a376f6b240e3baffb771a1450f4e", "placeholder": "\u200b", "style": "IPY_MODEL_bc06f72d1fd34de3afd5ba6ab3fde4b6", "value": " 23045/23045 [01:16&lt;00:00, 309.26it/s]"}}, "dc018f1038284d79a2decce740f03d36": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "153f57c4508940758818674a60edb1ab": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a2209d34b71e43ec971f293d00775bdd": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "dd4d0d9eff5c446a8229832b7461181a": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "89d08224a32d40b597f02817a1e2e30f": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "4668a376f6b240e3baffb771a1450f4e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bc06f72d1fd34de3afd5ba6ab3fde4b6": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3440a193a12f4cb39b7fee7d800164ea": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e154fb59aa63486894dc4450b174b163", "IPY_MODEL_49247b0136974931a8dbde834cf77990", "IPY_MODEL_517845c8f54c459eafba2a031f1428b8"], "layout": "IPY_MODEL_5fca5c76971b4eda8b8132feccbd9aa7"}}, "e154fb59aa63486894dc4450b174b163": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_4b54ad7398eb4abdae98f7a376fd9ab0", "placeholder": "\u200b", "style": "IPY_MODEL_23ee4530c6084723bddb7a17f288de32", "value": "Validation DataLoader 0: 100%"}}, "49247b0136974931a8dbde834cf77990": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_2eaa25bb15594daa9ea9f142bf09c00e", "max": 23045, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_1f419d7e1b6e45e7aae94f690cd4816b", "value": 23045}}, "517845c8f54c459eafba2a031f1428b8": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_225d9705982a451585a83a36e272d424", "placeholder": "\u200b", "style": "IPY_MODEL_97dbb371362040529eb2c642d11dbee9", "value": " 23045/23045 [01:16&lt;00:00, 301.34it/s]"}}, "5fca5c76971b4eda8b8132feccbd9aa7": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "4b54ad7398eb4abdae98f7a376fd9ab0": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "23ee4530c6084723bddb7a17f288de32": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "2eaa25bb15594daa9ea9f142bf09c00e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1f419d7e1b6e45e7aae94f690cd4816b": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "225d9705982a451585a83a36e272d424": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "97dbb371362040529eb2c642d11dbee9": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "43af2ee228434f798619109bcecf7978": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_a7ba9e3e6bdc41d6872974f0ffbfc732", "IPY_MODEL_76dbdc98d9f14ca3b825d01bb50ff7b1", "IPY_MODEL_e348b352d4dd471381952f7a5ad06307"], "layout": "IPY_MODEL_a4ca803458ee434f854f24c551d6fcd5"}}, "a7ba9e3e6bdc41d6872974f0ffbfc732": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_d35e96b7cab1412196e6a41b534a1893", "placeholder": "\u200b", "style": "IPY_MODEL_c6231eb7145c472eb7e0fefe85de0a34", "value": "Validation DataLoader 0: 100%"}}, "76dbdc98d9f14ca3b825d01bb50ff7b1": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_f7723241e1854ca0878838d46a90b2bf", "max": 23045, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_3575094025594bcf9c6c92e1c94a2937", "value": 23045}}, "e348b352d4dd471381952f7a5ad06307": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_194e22b6d4f84c6e932077c1d57e123c", "placeholder": "\u200b", "style": "IPY_MODEL_dbe69ebaf1504d2f85dda36c357c883c", "value": " 23045/23045 [01:16&lt;00:00, 312.07it/s]"}}, "a4ca803458ee434f854f24c551d6fcd5": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "d35e96b7cab1412196e6a41b534a1893": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c6231eb7145c472eb7e0fefe85de0a34": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "f7723241e1854ca0878838d46a90b2bf": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3575094025594bcf9c6c92e1c94a2937": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "194e22b6d4f84c6e932077c1d57e123c": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "dbe69ebaf1504d2f85dda36c357c883c": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}}
</script>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="wjlee-ling/nlp_log"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/nlp_log/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/nlp_log/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/nlp_log/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>언어학 전공한 NLP 개발자</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/wjlee-ling" target="_blank" title="wjlee-ling"><svg class="svg-icon grey"><use xlink:href="/nlp_log/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
