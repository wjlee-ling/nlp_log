<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://wjlee-ling.github.io/nlp_log/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wjlee-ling.github.io/nlp_log/" rel="alternate" type="text/html" /><updated>2022-07-07T21:37:32-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/feed.xml</id><title type="html">WJL in NLP</title><subtitle>언어학 전공한 NLP 개발자</subtitle><entry><title type="html">Byte-Pair Encoding (BPE) 알아보기</title><link href="https://wjlee-ling.github.io/nlp_log/word%20embedding/bpe/wordpiece/unigram/sentencepiece/subword/2022/07/07/_07_07_byte_pair_encoding.html" rel="alternate" type="text/html" title="Byte-Pair Encoding (BPE) 알아보기" /><published>2022-07-07T00:00:00-05:00</published><updated>2022-07-07T00:00:00-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/word%20embedding/bpe/wordpiece/unigram/sentencepiece/subword/2022/07/07/_07_07_byte_pair_encoding</id><author><name></name></author><category term="word embedding" /><category term="BPE" /><category term="wordpiece" /><category term="unigram" /><category term="sentencepiece" /><category term="subword" /><summary type="html"><![CDATA[BPE, WordPiece, Unigram, SentencePiece]]></summary></entry><entry><title type="html">CS224N Assignment 1</title><link href="https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/glove/2022/07/07/_05_17_cs224n_exploring_word_vectors.html" rel="alternate" type="text/html" title="CS224N Assignment 1" /><published>2022-07-07T00:00:00-05:00</published><updated>2022-07-07T00:00:00-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/glove/2022/07/07/_05_17_cs224n_exploring_word_vectors</id><author><name></name></author><category term="cs224n" /><category term="word embedding" /><category term="glove" /><summary type="html"><![CDATA[Exploring Word Vectors]]></summary></entry><entry><title type="html">Word2Vec Implementation</title><link href="https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation.html" rel="alternate" type="text/html" title="Word2Vec Implementation" /><published>2022-06-10T00:00:00-05:00</published><updated>2022-06-10T00:00:00-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/pytorch/2022/06/10/_06_22_kor_word2vec_implementation</id><author><name></name></author><category term="cs224n" /><category term="word embedding" /><category term="word2vec" /><category term="pytorch" /><summary type="html"><![CDATA[Word2Vec SGNS(Skip-Gram Negative Sampling) 구현하기]]></summary></entry><entry><title type="html">Word2Vec</title><link href="https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/2022/06/02/_06_02_cs224n_a2_word2vec.html" rel="alternate" type="text/html" title="Word2Vec" /><published>2022-06-02T00:00:00-05:00</published><updated>2022-06-02T00:00:00-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/cs224n/word%20embedding/word2vec/2022/06/02/_06_02_cs224n_a2_word2vec</id><author><name></name></author><category term="cs224n" /><category term="word embedding" /><category term="word2vec" /><summary type="html"><![CDATA[CS224n: Word2Vec과 a2과제 풀이]]></summary></entry><entry><title type="html">Tone&amp;amp;Fact 개발기</title><link href="https://wjlee-ling.github.io/nlp_log/nlp/gpt/aws/flask/kogpt/kogpt2-taf/2022/05/05/tone-and-fact-1.html" rel="alternate" type="text/html" title="Tone&amp;amp;Fact 개발기" /><published>2022-05-05T00:00:00-05:00</published><updated>2022-05-17T00:00:00-05:00</updated><id>https://wjlee-ling.github.io/nlp_log/nlp/gpt/aws/flask/kogpt/kogpt2-taf/2022/05/05/tone-and-fact-1</id><author><name></name></author><category term="nlp" /><category term="GPT" /><category term="AWS" /><category term="flask" /><category term="KoGPT" /><category term="KoGPT2-taf" /><summary type="html"><![CDATA[언론사별 사설 생성 모델]]></summary></entry></feed>